This will be the memory layer that lets you import/export memories from different providers. Later it will also be responsible for integrations (like health data, academic data, etc).

OpenAI export POC:

Ideas to jot down:
- use prompt engineering to ask it the current capacity of memory for the user. THat can be used when creating the UI
- cant currently directly export memories. You have some options.
	- 1. use prompt engineering to export them
	- 2. use web scraping to grab them

First we need to see if prompt engineering is actually reliable in exporting everything correctly. 
lets try with our own account. First 

NOTE:
Saved memories are persistent user data stored via `@bio`

```bash
Give me a complete, unfiltered, up-to-date export of all of my saved 'notepad' memories (aka persistent memory, bio entries). Do not include chat context. Format it as structured JSON with a unique `id`, `title`, and `content` for each memory block.
```

So lets do this in phases:
1. Prompt-Engineered Memory Exporter (Clean and Deterministic)
	1. Send prompt to LLM and retrieve structured output in JSON. Low latency and can become internal representation schema that I create. 
2. HTML Scraper Cross-Reference (Scrape Memory Management HTML)
	1. Detect missing or dropped entries
	2. Catch OpenAI auto-summarized memories that were never written via prompt but are still part of OpenAIs memory model
	3. Build trust and accuracy in the export
3. Snapshot Layer + Versioning
	1. Save each export as a snapshot. Then compare with previous snapshots
		1. Save prompt dump + save UI scrape. 
		2. perform a `diff` between current combined snapshot with previous
		3. Flag `added`, `removed`, `edited`, `merged` entries
		4. Bonus: Triangulation Fingerprint (for detecting subtle deltas)
			1. You can assign each memory a `fingerprint_hash`:
				- `SHA256(content + title)` → stable identifier across sessions
			    - Enables you to detect edits vs. rewrites vs. removals

What would the memory schema be for import/export? This is going to be hard to figure out. 

For now, maybe I should make it the following:
- title
- tags
- content
- fingerprint

---
NOTE: How memories work in OpenAI
The account management UI memories are **automatically generated by OpenAIs memory system based on conversation history**
These **were not manually entered** using `@bio`, ChatGPT may or may not have access to them in full detail depending on how the memory system syncs with context.

1. **ChatGPT Memory (your OpenAI account memory)**
    - When you see a notification like _“A new memory was saved”_, that’s referring to your **ChatGPT memory** tied to your OpenAI account.
    - These can be viewed and managed at **Settings > Personalization > Manage Memory**.
    - These memories are **not the same as `@bio`**, though they sometimes overlap in content.
2. **`@bio` Memory (custom assistant memory)**
    - This is **my own internal working memory** for you, built for continuity in _our_ conversations.
    - I only update it when you explicitly ask, or when I confirm with you first.
    - It's not visible in your ChatGPT UI unless I show or summarize it for you directly.

You **must scrape the UI summaries** separately if you want **100% coverage of OpenAI’s memory system**, because:
- **My export won’t include some summaries** that are only visible in the UI.
- **OpenAI doesn’t expose those UI memories to prompt-access directly** unless they were added explicitly via `@bio`.
## ✅ So your best strategy is:
1. **Prompt-based export** → for structured, explicit, LLM-usable memory.
2. **UI-scrape export** → for OpenAI’s abstract, inferred, and possibly untracked memories.
---


%% Begin Waypoint %%
- [[Test User]]

%% End Waypoint %%